# üì¢ Assistente de Voz em Portugu√™s (Flask + Whisper + TTS)

## Sum√°rio

- [Descri√ß√£o](#descri√ß√£o)
- [Funcionalidades](#funcionalidades)
- [Requisitos](#requisitos)
- [Instala√ß√£o](#instala√ß√£o)
- [Configura√ß√£o dos Modelos](#configura√ß√£o-dos-modelos)
- [Como Usar](#como-usar)
- [Arquitetura do Projeto](#arquitetura-do-projeto)
- [Customiza√ß√£o](#customiza√ß√£o)
- [Dicas de Performance](#dicas-de-performance)
- [Resolu√ß√£o de Problemas](#resolu√ß√£o-de-problemas)
- [Licen√ßa](#licen√ßa)
- [Refer√™ncias](#refer√™ncias)

---

## Descri√ß√£o

Este projeto √© um assistente de voz em portugu√™s, com interface web, que permite ao usu√°rio gravar ou enviar um √°udio, transcrev√™-lo usando o modelo Whisper (OpenAI) e responder com √°udio gerado por TTS (Text-to-Speech). O sistema √© otimizado para rodar em GPU (NVIDIA) e suporta sotaque brasileiro e portugu√™s europeu, dependendo do modelo TTS escolhido.

---

## Funcionalidades

- Interface web moderna (Bootstrap)
- Grava√ß√£o de √°udio via navegador ou upload de arquivo
- Transcri√ß√£o autom√°tica de √°udio usando Whisper
- Resposta em √°udio gerada por TTS (Text-to-Speech)
- Exibi√ß√£o dos tempos de processamento de cada etapa
- Suporte a m√∫ltiplos formatos de √°udio (webm, wav, mp3, etc)
- Otimizado para uso com GPU (CUDA/cuDNN)
- F√°cil customiza√ß√£o de modelos e sotaques

---

## Requisitos

### Hardware
- Placa de v√≠deo NVIDIA (recomendado para performance)
- 8GB+ RAM

### Sistema Operacional
- Ubuntu 22.04+ (testado tamb√©m em WSL2)

### Depend√™ncias do Sistema
- Python 3.8+
- ffmpeg
- CUDA 12.x
- cuDNN compat√≠vel

---

## Instala√ß√£o

### 1. Instale depend√™ncias do sistema

```bash
sudo apt-get update
sudo apt-get install -y python3-dev python3-setuptools python3-pip python3-wheel
sudo apt-get install -y build-essential libssl-dev libffi-dev
sudo apt-get install -y espeak-ng python3-espeak ffmpeg
```

### 2. Instale CUDA/cuDNN (se for usar GPU)

Siga as instru√ß√µes do README ou do script `setup.sh` para instalar CUDA e cuDNN compat√≠veis com sua GPU.

### 3. Crie e ative o ambiente virtual

```bash
python3 -m venv LLM
source LLM/bin/activate
```

### 4. Instale as depend√™ncias Python

```bash
pip install -r LLM/scripts/requirements.txt
```

> **Nota:** O arquivo `requirements.txt` j√° est√° ordenado para evitar conflitos de depend√™ncias.

---

## Configura√ß√£o dos Modelos

### Whisper (Reconhecimento de Fala)

- O modelo padr√£o √© o `small` (bom equil√≠brio entre velocidade e precis√£o).
- Para mais velocidade, use `base` ou `tiny`. Para mais precis√£o, use `medium` ou `large`.

### TTS (S√≠ntese de Voz)

- Para portugu√™s brasileiro mais natural, use:  
  `tts_models/pt/br/vits-neural`
- Para portugu√™s europeu, use:  
  `tts_models/pt/cv/vits`
- Para flexibilidade e vozes diferentes, use:  
  `tts_models/multilingual/multi-dataset/your_tts`

Altere o par√¢metro `model_name` na inicializa√ß√£o do TTS em `app.py` conforme desejado.

---

## Como Usar

1. Inicie o servidor Flask:
   ```bash
   python LLM/scripts/app.py
   ```
2. Acesse no navegador:  
   [http://localhost:5000](http://localhost:5000)

3. Grave um √°udio ou fa√ßa upload de um arquivo.

4. Aguarde a transcri√ß√£o e a resposta em √°udio.  
   Os tempos de processamento de cada etapa aparecer√£o na tela.

---

## Arquitetura do Projeto

```
LLM/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                # Backend Flask + l√≥gica de processamento
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt      # Depend√™ncias Python
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh              # Script de instala√ß√£o automatizada
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îî‚îÄ‚îÄ index.html        # Interface web (frontend)
‚îú‚îÄ‚îÄ static/                   # (opcional) Arquivos est√°ticos
‚îú‚îÄ‚îÄ services/                 # (opcional) Servi√ßos auxiliares
‚îî‚îÄ‚îÄ README.md                 # Documenta√ß√£o
```

### Fluxo de Processamento

1. **Frontend**: Grava√ß√£o/upload ‚Üí Envio do √°udio para `/process_audio`
2. **Backend**:
   - Salva e converte o √°udio para WAV (ffmpeg)
   - Transcreve com Whisper
   - Gera resposta com TTS
   - Codifica resposta em base64
   - Retorna transcri√ß√£o, √°udio e tempos de processamento
3. **Frontend**: Exibe transcri√ß√£o, toca resposta e mostra tempos

---

## Customiza√ß√£o

### Trocar modelo Whisper
No `app.py`, altere:
```python
whisper_model = WhisperModel(
    model_size_or_path="small",  # ou "base", "tiny", "medium", "large"
    ...
)
```

### Trocar modelo TTS
No `app.py`, altere:
```python
tts = TTS(
    model_name="tts_models/pt/br/vits-neural",  # ou outro modelo
    ...
)
```

### Trocar voz (YourTTS)
```python
tts.tts_to_file(
    text=response_text,
    file_path=temp_response,
    speaker='pt_001'  # Veja tts.speakers para op√ß√µes
)
```

---

## Dicas de Performance

- Use GPU (CUDA) para Whisper e TTS para m√°xima velocidade.
- Use modelos menores para respostas mais r√°pidas.
- Reduza o par√¢metro `beam_size` na transcri√ß√£o para acelerar.
- Ajuste `cpu_threads` e `num_workers` conforme seu hardware.

---

## Resolu√ß√£o de Problemas

### Erro: `Format not recognised` ao processar √°udio
- Certifique-se que o ffmpeg est√° instalado.
- O frontend pode enviar `.webm` ou `.mp3`. O backend converte para `.wav` automaticamente.

### Erro: `Model is not multi-lingual but language is provided`
- N√£o passe o par√¢metro `language` para modelos TTS espec√≠ficos de um idioma.

### √Åudio TTS muito rob√≥tico ou sotaque de Portugal
- Troque para o modelo `tts_models/pt/br/vits-neural` ou `your_tts` para voz brasileira.

### CUDA/cuDNN n√£o reconhecido
- Verifique se as vers√µes instaladas s√£o compat√≠veis com sua GPU e PyTorch.

### Demora na transcri√ß√£o
- Use modelos menores do Whisper (`small`, `base`, `tiny`).

---

## Licen√ßa

Este projeto utiliza modelos open-source sob licen√ßas Apache 2.0 e MIT. Consulte as licen√ßas dos modelos utilizados para detalhes.

---

## Refer√™ncias

- [Whisper (OpenAI) - HuggingFace](https://huggingface.co/openai/whisper-medium/blob/main/README.md)
- [Coqui TTS - Modelos](https://github.com/coqui-ai/TTS)
- [Bootstrap](https://getbootstrap.com/)
- [ffmpeg](https://ffmpeg.org/) 